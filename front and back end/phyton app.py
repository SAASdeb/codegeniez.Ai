# app.py
"""
Flask backend for a SaaS AI site-builder.
- Uses Convex Python client to store prompts, examples, and generated projects.
- /api/generate -> Generate website code from prompt (uses prompt-template or OpenAI)
- /api/examples -> store/list training examples
- /api/train -> (optional) kickoff a fine-tune job (example stub for OpenAI)
"""

import os
import json
from flask import Flask, request, jsonify, send_from_directory
from convex import ConvexClient
from dotenv import load_dotenv

# Load env
load_dotenv(".env")
CONVEX_URL = os.getenv("CONVEX_URL")  # set from convex dev or prod deployment
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", None)  # optional if you use OpenAI

# Init Convex client
if not CONVEX_URL:
    raise RuntimeError("Set CONVEX_URL in .env (see Convex quickstart).")
convex = ConvexClient(CONVEX_URL)

app = Flask(__name__, static_folder=".", static_url_path="/")

# Simple prompt-to-site generator (fallback if no external model)
SIMPLE_TEMPLATE = """<!-- Generated site for: {title} -->
<!doctype html>
<html>
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>{title}</title>
  <style>
    body {{ font-family: Inter, system-ui, -apple-system, Roboto, "Segoe UI", sans-serif; margin:0; padding:0; background:#f6f8fb; color:#0b1; }}
    header {{ background: #00008B; color: white; padding: 28px 24px; }}
    .container {{ max-width: 1024px; margin: 28px auto; padding: 0 16px; }}
    .hero {{ background: white; padding: 28px; border-radius: 10px; box-shadow: 0 6px 18px rgba(10,20,40,0.06); }}
    .btn {{ display:inline-block; padding: 10px 16px; border-radius:8px; background:#00008B; color:white; text-decoration:none; }}
  </style>
</head>
<body>
  <header>
    <div class="container">
      <h1>{title}</h1>
    </div>
  </header>
  <main class="container">
    <section class="hero">
      <h2>{headline}</h2>
      <p>{description}</p>
      <a class="btn" href="#contact">Contact</a>
    </section>
  </main>
  <footer style="text-align:center; padding:28px; color:#666;">
    <small>Generated by SaaS AI · {title}</small>
  </footer>
</body>
</html>
"""

def simple_generate(prompt_text: str):
    """Create quick HTML from structured prompt (fallback)."""
    # Basic heuristic: split prompt into title/headline/description by lines or commas
    lines = [l.strip() for l in prompt_text.splitlines() if l.strip()]
    title = lines[0] if lines else "My Website"
    headline = lines[1] if len(lines) > 1 else "We build quality websites."
    description = " ".join(lines[2:]) if len(lines) > 2 else "Generated by SaaS AI — edit this to customize."
    html = SIMPLE_TEMPLATE.format(title=title, headline=headline, description=description)
    return {
        "html": html,
        "assets": {},  # placeholder for images/css
        "meta": {"title": title}
    }

@app.route("/")
def index():
    # serve frontend file
    return send_from_directory(".", "frontend.html")

@app.route("/api/generate", methods=["POST"])
def api_generate():
    """
    Request body: { "prompt": "...", "options": { ... } }
    Response: { "id": "<convex_id>", "html": "...", "meta": {...} }
    """
    data = request.get_json(force=True)
    prompt = data.get("prompt", "").strip()
    options = data.get("options", {}) or {}

    if not prompt:
        return jsonify({"error": "Prompt is required."}), 400

    # 1) Save prompt to Convex for analytics/training
    try:
        saved = convex.mutation("examples:insert", {"prompt": prompt, "options": options})
        # Note: depending on how you structure convex functions, names may differ.
    except Exception:
        # If you don't have mutations set up in Convex yet, we keep going but log.
        saved = None

    # 2) Generate site code
    html_result = None
    try:
        # If OPENAI_API_KEY is set, use it (example using requests). If not, fallback to simple_generate.
        if OPENAI_API_KEY:
            # Example: call OpenAI Chat Completion (pseudo). Replace this with actual client code.
            # We keep it as a safe, replaceable template — do not call remote APIs here.
            # Example prompt pattern for model:
            generation_prompt = f"""
            You are an expert website builder. Given the user's prompt below, produce a single HTML file (no external dependencies),
            with inline CSS and a small inline JS if needed. Do not include any explanation text — return only the HTML.
            User prompt:
            \"\"\"{prompt}\"\"\"
            """
            # If you use openai package:
            # import openai
            # openai.api_key = OPENAI_API_KEY
            # resp = openai.ChatCompletion.create(model="gpt-4o-mini", messages=[{"role":"system","content":"You are an expert web dev."}, {"role":"user","content": generation_prompt}], temperature=0.2)
            # html_result = resp["choices"][0]["message"]["content"]
            # For this repo, fallback:
            html_result = simple_generate(prompt)
        else:
            html_result = simple_generate(prompt)
    except Exception as e:
        return jsonify({"error": "Generation failed", "details": str(e)}), 500

    # 3) Save generated artifact to Convex
    try:
        project_record = {
            "prompt": prompt,
            "html": html_result if isinstance(html_result, str) else html_result.get("html"),
            "meta": {"engine": "simple_template" if not OPENAI_API_KEY else "openai_stub"}
        }
        saved_project = convex.mutation("projects:insert", project_record)
    except Exception:
        saved_project = None

    # Respond with html and convex ids (if available)
    return jsonify({
        "id": saved_project or saved or None,
        "html": html_result if isinstance(html_result, str) else html_result.get("html"),
        "meta": project_record["meta"]
    }), 200

@app.route("/api/examples", methods=["GET", "POST"])
def api_examples():
    if request.method == "GET":
        # return latest examples from Convex
        try:
            ex = convex.query("examples:list")
            return jsonify({"examples": ex})
        except Exception:
            return jsonify({"examples": []})
    else:
        payload = request.get_json(force=True)
        prompt = payload.get("prompt")
        result_html = payload.get("html")
        if not prompt or not result_html:
            return jsonify({"error": "prompt and html required"}), 400
        # Insert example for training
        try:
            r = convex.mutation("examples:insert", {"prompt": prompt, "html": result_html})
            return jsonify({"ok": True, "id": r})
        except Exception as e:
            return jsonify({"ok": False, "error": str(e)}), 500

@app.route("/api/train", methods=["POST"])
def api_train():
    """
    Optional endpoint to kick off training/fine-tune using stored examples.
    This is a stub showing how you might pass Convex examples to a fine-tune API (e.g. OpenAI).
    """
    if not OPENAI_API_KEY:
        return jsonify({"error": "No OpenAI API key configured on server. Training not available."}), 400

    # Example flow:
    # 1) Query examples from Convex
    try:
        examples = convex.query("examples:list")
    except Exception:
        examples = []

    # 2) Convert examples into training dataset format (provider-specific)
    # (For OpenAI fine-tune: create JSONL with {"prompt": "...", "completion": "..."})
    # Here we just return the prepared payload as an example
    training_payload = []
    for ex in examples:
        p = ex.get("prompt")
        h = ex.get("html")
        if p and h:
            training_payload.append({"prompt": p + "\n\n###\n\n", "completion": h})

    # In real usage: upload to the provider, create fine-tune, monitor status.
    # Return prepared payload sample so frontend can display.
    return jsonify({"prepared_examples": len(training_payload), "examples_preview": training_payload[:5]})

if __name__ == "__main__":
    app.run(debug=True, port=int(os.getenv("PORT", 5000)))
